{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.utils import shuffle\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, MultiTaskElasticNet, MultiTaskLasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, log_loss, accuracy_score\n",
    "import time\n",
    "# from sklearn.manifold import TSNE\n",
    "import joblib\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.load('encoded_data_clip_fast/Xtrain.npy')\n",
    "Xdev = np.load('encoded_data_clip_fast/Xdev.npy')\n",
    "# Xtest = np.load('data/Xtest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.load('encoded_data_clip_fast/ytrain.npy')\n",
    "ydev = np.load('encoded_data_clip_fast/ydev.npy')\n",
    "# ytest = np.load('data/ytest.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0906 21:14:07.678675 139730131195648 deprecation.py:506] From /data/home/t-chepan/env/newlab/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "n_features = Xtrain.shape[1]\n",
    "n_outputs = ytrain.shape[1]\n",
    "\n",
    "inputs = keras.Input(shape=(n_features,), name='input_features')\n",
    "x = layers.Dense(128, activation='relu', name='dense_1')(inputs)\n",
    "x = layers.Dense(128, activation='relu', name='dense_2')(x)\n",
    "x = layers.Dense(128, activation='relu', name='dense_3')(x)\n",
    "x = layers.Dense(128, activation='relu', name='dense_4')(x)\n",
    "x = layers.Dense(128, activation='relu', name='dense_5')(x)\n",
    "outputs = layers.Dense(n_outputs, name='predictions')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_features (InputLayer)  [(None, 446)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               57216     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 124,812\n",
      "Trainable params: 124,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(0.0001349800908161859)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=opt,\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full training size is 1358666\n",
      "selected training size is 1358\n",
      "Train on 1358 samples, validate on 13863 samples\n",
      "Epoch 1/100\n",
      "1358/1358 [==============================] - 1s 576us/sample - loss: 0.1749 - mean_squared_error: 0.1749 - val_loss: 0.1271 - val_mean_squared_error: 0.1271\n",
      "Epoch 2/100\n",
      "1358/1358 [==============================] - 0s 262us/sample - loss: 0.1157 - mean_squared_error: 0.1157 - val_loss: 0.1119 - val_mean_squared_error: 0.1119\n",
      "Epoch 3/100\n",
      "1358/1358 [==============================] - 0s 252us/sample - loss: 0.0916 - mean_squared_error: 0.0916 - val_loss: 0.0969 - val_mean_squared_error: 0.0969\n",
      "Epoch 4/100\n",
      "1358/1358 [==============================] - 0s 262us/sample - loss: 0.0747 - mean_squared_error: 0.0747 - val_loss: 0.0843 - val_mean_squared_error: 0.0843\n",
      "Epoch 5/100\n",
      "1358/1358 [==============================] - 0s 286us/sample - loss: 0.0636 - mean_squared_error: 0.0636 - val_loss: 0.0744 - val_mean_squared_error: 0.0744\n",
      "Epoch 6/100\n",
      "1358/1358 [==============================] - 0s 246us/sample - loss: 0.0564 - mean_squared_error: 0.0564 - val_loss: 0.0686 - val_mean_squared_error: 0.0686\n",
      "Epoch 7/100\n",
      "1358/1358 [==============================] - 0s 245us/sample - loss: 0.0521 - mean_squared_error: 0.0521 - val_loss: 0.0655 - val_mean_squared_error: 0.0655\n",
      "Epoch 8/100\n",
      "1358/1358 [==============================] - 0s 248us/sample - loss: 0.0492 - mean_squared_error: 0.0492 - val_loss: 0.0627 - val_mean_squared_error: 0.0627\n",
      "Epoch 9/100\n",
      "1358/1358 [==============================] - 0s 247us/sample - loss: 0.0469 - mean_squared_error: 0.0469 - val_loss: 0.0619 - val_mean_squared_error: 0.0619\n",
      "Epoch 10/100\n",
      "1358/1358 [==============================] - 0s 258us/sample - loss: 0.0452 - mean_squared_error: 0.0452 - val_loss: 0.0602 - val_mean_squared_error: 0.0602\n",
      "Epoch 11/100\n",
      "1358/1358 [==============================] - 0s 249us/sample - loss: 0.0436 - mean_squared_error: 0.0436 - val_loss: 0.0601 - val_mean_squared_error: 0.0601\n",
      "Epoch 12/100\n",
      "1358/1358 [==============================] - 0s 270us/sample - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "Epoch 13/100\n",
      "1358/1358 [==============================] - 0s 259us/sample - loss: 0.0413 - mean_squared_error: 0.0413 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 14/100\n",
      "1358/1358 [==============================] - 0s 254us/sample - loss: 0.0395 - mean_squared_error: 0.0395 - val_loss: 0.0578 - val_mean_squared_error: 0.0578\n",
      "Epoch 15/100\n",
      "1358/1358 [==============================] - 0s 267us/sample - loss: 0.0405 - mean_squared_error: 0.0405 - val_loss: 0.0579 - val_mean_squared_error: 0.0579\n",
      "Epoch 16/100\n",
      "1358/1358 [==============================] - 0s 258us/sample - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0573 - val_mean_squared_error: 0.0573\n",
      "Epoch 17/100\n",
      "1358/1358 [==============================] - 0s 271us/sample - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0568 - val_mean_squared_error: 0.0568\n",
      "Epoch 18/100\n",
      "1358/1358 [==============================] - 0s 249us/sample - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0568 - val_mean_squared_error: 0.0568\n",
      "Epoch 19/100\n",
      "1358/1358 [==============================] - 0s 258us/sample - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0564 - val_mean_squared_error: 0.0564\n",
      "Epoch 20/100\n",
      "1358/1358 [==============================] - 0s 256us/sample - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0567 - val_mean_squared_error: 0.0567\n",
      "Epoch 21/100\n",
      "1358/1358 [==============================] - 0s 253us/sample - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0566 - val_mean_squared_error: 0.0566\n",
      "Epoch 22/100\n",
      "1358/1358 [==============================] - 0s 271us/sample - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0567 - val_mean_squared_error: 0.0567\n",
      "Epoch 23/100\n",
      "1358/1358 [==============================] - 0s 266us/sample - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0565 - val_mean_squared_error: 0.0565\n",
      "Epoch 24/100\n",
      "1358/1358 [==============================] - 0s 273us/sample - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0563 - val_mean_squared_error: 0.0563\n",
      "Epoch 25/100\n",
      "1358/1358 [==============================] - 0s 258us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0562 - val_mean_squared_error: 0.0562\n",
      "Epoch 26/100\n",
      "1358/1358 [==============================] - 0s 277us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0573 - val_mean_squared_error: 0.0573\n",
      "Epoch 27/100\n",
      "1358/1358 [==============================] - 0s 260us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0563 - val_mean_squared_error: 0.0563\n",
      "Epoch 28/100\n",
      "1358/1358 [==============================] - 0s 249us/sample - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0571 - val_mean_squared_error: 0.0571\n",
      "Epoch 29/100\n",
      "1358/1358 [==============================] - 0s 250us/sample - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.0562 - val_mean_squared_error: 0.0562\n",
      "Epoch 30/100\n",
      "1358/1358 [==============================] - 0s 256us/sample - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.0570 - val_mean_squared_error: 0.0570\n",
      "used time in 12.48844027519226 seconds.\n",
      "selected training size is 2717\n",
      "Train on 2717 samples, validate on 13863 samples\n",
      "Epoch 1/100\n",
      "2717/2717 [==============================] - 0s 172us/sample - loss: 0.0420 - mean_squared_error: 0.0420 - val_loss: 0.0545 - val_mean_squared_error: 0.0545\n",
      "Epoch 2/100\n",
      "2717/2717 [==============================] - 0s 150us/sample - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0535 - val_mean_squared_error: 0.0535\n",
      "Epoch 3/100\n",
      "2717/2717 [==============================] - 0s 147us/sample - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0538 - val_mean_squared_error: 0.0538\n",
      "Epoch 4/100\n",
      "2717/2717 [==============================] - 0s 142us/sample - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
      "Epoch 5/100\n",
      "2717/2717 [==============================] - 0s 149us/sample - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0534 - val_mean_squared_error: 0.0534\n",
      "Epoch 6/100\n",
      "2717/2717 [==============================] - 0s 149us/sample - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0527 - val_mean_squared_error: 0.0527\n",
      "Epoch 7/100\n",
      "2717/2717 [==============================] - 0s 150us/sample - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
      "Epoch 8/100\n",
      "2717/2717 [==============================] - 0s 149us/sample - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0537 - val_mean_squared_error: 0.0537\n",
      "Epoch 9/100\n",
      "2717/2717 [==============================] - 0s 147us/sample - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0526 - val_mean_squared_error: 0.0526\n",
      "Epoch 10/100\n",
      "2717/2717 [==============================] - 0s 153us/sample - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0542 - val_mean_squared_error: 0.0542\n",
      "Epoch 11/100\n",
      "2717/2717 [==============================] - 0s 149us/sample - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0531 - val_mean_squared_error: 0.0531\n",
      "Epoch 12/100\n",
      "2717/2717 [==============================] - 0s 148us/sample - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0538 - val_mean_squared_error: 0.0538\n",
      "Epoch 13/100\n",
      "2717/2717 [==============================] - 0s 146us/sample - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
      "Epoch 14/100\n",
      "2717/2717 [==============================] - 0s 143us/sample - loss: 0.0316 - mean_squared_error: 0.0316 - val_loss: 0.0538 - val_mean_squared_error: 0.0538\n",
      "used time in 5.736653566360474 seconds.\n",
      "selected training size is 5434\n",
      "Train on 5434 samples, validate on 13863 samples\n",
      "Epoch 1/100\n",
      "5434/5434 [==============================] - 1s 95us/sample - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0498 - val_mean_squared_error: 0.0498\n",
      "Epoch 2/100\n",
      "5434/5434 [==============================] - 1s 97us/sample - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5434/5434 [==============================] - 1s 97us/sample - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
      "Epoch 4/100\n",
      "5434/5434 [==============================] - 1s 99us/sample - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
      "Epoch 5/100\n",
      "5434/5434 [==============================] - 1s 98us/sample - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
      "Epoch 6/100\n",
      "5434/5434 [==============================] - 1s 98us/sample - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
      "Epoch 7/100\n",
      "5434/5434 [==============================] - 1s 96us/sample - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
      "Epoch 8/100\n",
      "5434/5434 [==============================] - 1s 97us/sample - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
      "Epoch 9/100\n",
      "5434/5434 [==============================] - 1s 107us/sample - loss: 0.0320 - mean_squared_error: 0.0320 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
      "Epoch 10/100\n",
      "5434/5434 [==============================] - 1s 97us/sample - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
      "Epoch 11/100\n",
      "5434/5434 [==============================] - 1s 94us/sample - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
      "Epoch 12/100\n",
      "5434/5434 [==============================] - 1s 95us/sample - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.0501 - val_mean_squared_error: 0.0501\n",
      "used time in 6.3988213539123535 seconds.\n",
      "selected training size is 10869\n",
      "Train on 10869 samples, validate on 13863 samples\n",
      "Epoch 1/100\n",
      "10869/10869 [==============================] - 1s 67us/sample - loss: 0.0410 - mean_squared_error: 0.0410 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
      "Epoch 2/100\n",
      "10869/10869 [==============================] - 1s 71us/sample - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
      "Epoch 3/100\n",
      "10869/10869 [==============================] - 1s 70us/sample - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
      "Epoch 4/100\n",
      "10869/10869 [==============================] - 1s 68us/sample - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
      "Epoch 5/100\n",
      "10869/10869 [==============================] - 1s 67us/sample - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
      "Epoch 6/100\n",
      "10869/10869 [==============================] - 1s 78us/sample - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
      "Epoch 7/100\n",
      "10869/10869 [==============================] - 1s 70us/sample - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
      "Epoch 8/100\n",
      "10869/10869 [==============================] - 1s 68us/sample - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
      "Epoch 9/100\n",
      "10869/10869 [==============================] - 1s 68us/sample - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
      "Epoch 10/100\n",
      "10869/10869 [==============================] - 1s 68us/sample - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
      "Epoch 11/100\n",
      "10869/10869 [==============================] - 1s 72us/sample - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
      "Epoch 12/100\n",
      "10869/10869 [==============================] - 1s 70us/sample - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
      "used time in 9.147571802139282 seconds.\n",
      "selected training size is 21738\n",
      "Train on 21738 samples, validate on 13863 samples\n",
      "Epoch 1/100\n",
      "21738/21738 [==============================] - 1s 57us/sample - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
      "Epoch 2/100\n",
      "21738/21738 [==============================] - 1s 58us/sample - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
      "Epoch 3/100\n",
      "21738/21738 [==============================] - 1s 56us/sample - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0425 - val_mean_squared_error: 0.0425\n",
      "Epoch 4/100\n",
      "21738/21738 [==============================] - 1s 55us/sample - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
      "Epoch 5/100\n",
      "21738/21738 [==============================] - 1s 60us/sample - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0422 - val_mean_squared_error: 0.0422\n",
      "Epoch 6/100\n",
      "21738/21738 [==============================] - 1s 58us/sample - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0422 - val_mean_squared_error: 0.0422\n",
      "Epoch 7/100\n",
      "21738/21738 [==============================] - 1s 55us/sample - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
      "Epoch 8/100\n",
      "21738/21738 [==============================] - 1s 57us/sample - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
      "Epoch 9/100\n",
      "21738/21738 [==============================] - 1s 57us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0424 - val_mean_squared_error: 0.0424\n",
      "used time in 11.181945323944092 seconds.\n",
      "selected training size is 27173\n",
      "Train on 27173 samples, validate on 13863 samples\n",
      "Epoch 1/100\n",
      "27173/27173 [==============================] - 1s 54us/sample - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0419 - val_mean_squared_error: 0.0419\n",
      "Epoch 2/100\n",
      "27173/27173 [==============================] - 1s 54us/sample - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0417 - val_mean_squared_error: 0.0417\n",
      "Epoch 3/100\n",
      "27173/27173 [==============================] - 1s 53us/sample - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0419 - val_mean_squared_error: 0.0419\n",
      "Epoch 4/100\n",
      "27173/27173 [==============================] - 2s 56us/sample - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
      "Epoch 5/100\n",
      "27173/27173 [==============================] - 1s 52us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0420 - val_mean_squared_error: 0.0420\n",
      "Epoch 6/100\n",
      "27173/27173 [==============================] - 1s 52us/sample - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
      "Epoch 7/100\n",
      "27173/27173 [==============================] - 1s 53us/sample - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
      "used time in 10.200230121612549 seconds.\n",
      "selected training size is 40759\n",
      "Train on 40759 samples, validate on 13863 samples\n",
      "Epoch 1/100\n",
      "40759/40759 [==============================] - 2s 49us/sample - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0410 - val_mean_squared_error: 0.0410\n",
      "Epoch 2/100\n",
      "40759/40759 [==============================] - 2s 49us/sample - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0408 - val_mean_squared_error: 0.0408\n",
      "Epoch 3/100\n",
      "40759/40759 [==============================] - 2s 51us/sample - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0413 - val_mean_squared_error: 0.0413\n",
      "Epoch 4/100\n",
      "40759/40759 [==============================] - 2s 51us/sample - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0409 - val_mean_squared_error: 0.0409\n",
      "Epoch 5/100\n",
      "40759/40759 [==============================] - 2s 50us/sample - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0411 - val_mean_squared_error: 0.0411\n",
      "Epoch 6/100\n",
      "40759/40759 [==============================] - 2s 53us/sample - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0408 - val_mean_squared_error: 0.0408\n",
      "Epoch 7/100\n",
      "40759/40759 [==============================] - 2s 54us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0408 - val_mean_squared_error: 0.0408\n",
      "used time in 14.576912641525269 seconds.\n",
      "selected training size is 54346\n",
      "Train on 54346 samples, validate on 13863 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54346/54346 [==============================] - 3s 50us/sample - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0403 - val_mean_squared_error: 0.0403\n",
      "Epoch 2/100\n",
      "54346/54346 [==============================] - 3s 50us/sample - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0400 - val_mean_squared_error: 0.0400\n",
      "Epoch 3/100\n",
      "54346/54346 [==============================] - 3s 50us/sample - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0401 - val_mean_squared_error: 0.0401\n",
      "Epoch 4/100\n",
      "54346/54346 [==============================] - 3s 51us/sample - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0399 - val_mean_squared_error: 0.0399\n",
      "Epoch 5/100\n",
      "54346/54346 [==============================] - 3s 48us/sample - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0400 - val_mean_squared_error: 0.0400\n",
      "Epoch 6/100\n",
      "54346/54346 [==============================] - 3s 49us/sample - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0398 - val_mean_squared_error: 0.0398\n",
      "Epoch 7/100\n",
      "54346/54346 [==============================] - 3s 48us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0402 - val_mean_squared_error: 0.0402\n",
      "Epoch 8/100\n",
      "54346/54346 [==============================] - 3s 48us/sample - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0402 - val_mean_squared_error: 0.0402\n",
      "Epoch 9/100\n",
      "54346/54346 [==============================] - 3s 49us/sample - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0406 - val_mean_squared_error: 0.0406\n",
      "Epoch 10/100\n",
      "54346/54346 [==============================] - 3s 48us/sample - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0401 - val_mean_squared_error: 0.0401\n",
      "Epoch 11/100\n",
      "54346/54346 [==============================] - 3s 48us/sample - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0405 - val_mean_squared_error: 0.0405\n",
      "used time in 29.42480707168579 seconds.\n",
      "selected training size is 108693\n",
      "Train on 108693 samples, validate on 13863 samples\n",
      "Epoch 1/100\n",
      "108693/108693 [==============================] - 5s 45us/sample - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0386 - val_mean_squared_error: 0.0386\n",
      "Epoch 2/100\n",
      "108693/108693 [==============================] - 5s 45us/sample - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0384 - val_mean_squared_error: 0.0384\n",
      "Epoch 3/100\n",
      "108693/108693 [==============================] - 5s 47us/sample - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
      "Epoch 4/100\n",
      "108693/108693 [==============================] - 5s 46us/sample - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0384 - val_mean_squared_error: 0.0384\n",
      "Epoch 5/100\n",
      "108693/108693 [==============================] - 5s 47us/sample - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
      "Epoch 6/100\n",
      "108693/108693 [==============================] - 5s 45us/sample - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
      "Epoch 7/100\n",
      "108693/108693 [==============================] - 5s 45us/sample - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0383 - val_mean_squared_error: 0.0383\n",
      "Epoch 8/100\n",
      "108693/108693 [==============================] - 5s 45us/sample - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0382 - val_mean_squared_error: 0.0382\n",
      "Epoch 9/100\n",
      "108693/108693 [==============================] - 5s 47us/sample - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
      "Epoch 10/100\n",
      "108693/108693 [==============================] - 5s 49us/sample - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0382 - val_mean_squared_error: 0.0382\n",
      "Epoch 11/100\n",
      "108693/108693 [==============================] - 5s 47us/sample - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0382 - val_mean_squared_error: 0.0382\n",
      "Epoch 12/100\n",
      "108693/108693 [==============================] - 5s 47us/sample - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0384 - val_mean_squared_error: 0.0384\n",
      "Epoch 13/100\n",
      "108693/108693 [==============================] - 5s 47us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0385 - val_mean_squared_error: 0.0385\n",
      "Epoch 14/100\n",
      "108693/108693 [==============================] - 5s 45us/sample - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0384 - val_mean_squared_error: 0.0384\n",
      "used time in 70.40189552307129 seconds.\n",
      "selected training size is 135866\n",
      "Train on 135866 samples, validate on 13863 samples\n",
      "Epoch 1/100\n",
      "135866/135866 [==============================] - 6s 45us/sample - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0380 - val_mean_squared_error: 0.0380\n",
      "Epoch 2/100\n",
      "135866/135866 [==============================] - 6s 46us/sample - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
      "Epoch 3/100\n",
      "135866/135866 [==============================] - 7s 50us/sample - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
      "Epoch 4/100\n",
      "135866/135866 [==============================] - 7s 49us/sample - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
      "Epoch 5/100\n",
      "135866/135866 [==============================] - 7s 51us/sample - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
      "Epoch 6/100\n",
      "135866/135866 [==============================] - 7s 50us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0380 - val_mean_squared_error: 0.0380\n",
      "Epoch 7/100\n",
      "135866/135866 [==============================] - 7s 54us/sample - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
      "Epoch 8/100\n",
      "135866/135866 [==============================] - 8s 56us/sample - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0382 - val_mean_squared_error: 0.0382\n",
      "used time in 54.61238718032837 seconds.\n",
      "selected training size is 203799\n",
      "Train on 203799 samples, validate on 13863 samples\n",
      "Epoch 1/100\n",
      "203799/203799 [==============================] - 11s 52us/sample - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
      "Epoch 2/100\n",
      "203799/203799 [==============================] - 12s 60us/sample - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0374 - val_mean_squared_error: 0.0374\n",
      "Epoch 3/100\n",
      "203799/203799 [==============================] - 12s 57us/sample - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
      "Epoch 4/100\n",
      "203799/203799 [==============================] - 11s 53us/sample - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
      "Epoch 5/100\n",
      "203799/203799 [==============================] - 11s 54us/sample - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
      "Epoch 6/100\n",
      "203799/203799 [==============================] - 10s 51us/sample - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
      "Epoch 7/100\n",
      "203799/203799 [==============================] - 11s 54us/sample - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
      "Epoch 8/100\n",
      "203799/203799 [==============================] - 11s 53us/sample - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
      "Epoch 9/100\n",
      "203799/203799 [==============================] - 11s 54us/sample - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
      "Epoch 10/100\n",
      "203799/203799 [==============================] - 10s 51us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
      "Epoch 11/100\n",
      "203799/203799 [==============================] - 11s 55us/sample - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
      "used time in 121.59721636772156 seconds.\n",
      "selected training size is 271733\n",
      "Train on 271733 samples, validate on 13863 samples\n",
      "Epoch 1/100\n",
      "271733/271733 [==============================] - 15s 55us/sample - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "271733/271733 [==============================] - 14s 52us/sample - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
      "Epoch 3/100\n",
      "271733/271733 [==============================] - 14s 53us/sample - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
      "Epoch 4/100\n",
      "271733/271733 [==============================] - 15s 57us/sample - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0368 - val_mean_squared_error: 0.0368\n",
      "Epoch 5/100\n",
      "271733/271733 [==============================] - 15s 54us/sample - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0367 - val_mean_squared_error: 0.0367\n",
      "Epoch 6/100\n",
      "271733/271733 [==============================] - 15s 56us/sample - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0368 - val_mean_squared_error: 0.0368\n",
      "Epoch 7/100\n",
      "271733/271733 [==============================] - 15s 56us/sample - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
      "Epoch 8/100\n",
      "271733/271733 [==============================] - 16s 60us/sample - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0366 - val_mean_squared_error: 0.0366\n",
      "Epoch 9/100\n",
      "271733/271733 [==============================] - 16s 59us/sample - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
      "Epoch 10/100\n",
      "271733/271733 [==============================] - 16s 60us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0368 - val_mean_squared_error: 0.0368\n",
      "Epoch 11/100\n",
      "271733/271733 [==============================] - 16s 59us/sample - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0366 - val_mean_squared_error: 0.0366\n",
      "Epoch 12/100\n",
      "271733/271733 [==============================] - 15s 57us/sample - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0370 - val_mean_squared_error: 0.0370\n",
      "Epoch 13/100\n",
      "271733/271733 [==============================] - 15s 54us/sample - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
      "Epoch 14/100\n",
      "271733/271733 [==============================] - 15s 56us/sample - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
      "Epoch 15/100\n",
      "271733/271733 [==============================] - 17s 61us/sample - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
      "Epoch 16/100\n",
      "271733/271733 [==============================] - 16s 58us/sample - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0374 - val_mean_squared_error: 0.0374\n",
      "used time in 246.6448106765747 seconds.\n"
     ]
    }
   ],
   "source": [
    "data_size = [0.001, 0.002, 0.004, 0.008, 0.016, 0.02, \n",
    "             0.03, 0.04, 0.08, 0.10, 0.15, 0.20,\n",
    "#              0.21, 0.22\n",
    "            ]\n",
    "\n",
    "## NN model\n",
    "nn_results = []\n",
    "full_size = Xtrain.shape[0]\n",
    "print('full training size is {}'.format(full_size))\n",
    "# Xdev = Xdev[:100,:]\n",
    "# ydev = ydev[:100,:]\n",
    "\n",
    "\n",
    "## run the nn model with certain size of training data\n",
    "\n",
    "for i in data_size[:]:\n",
    "    t1 = time.time()\n",
    "    results = {}\n",
    "    \n",
    "    selected_size = int(full_size * i)\n",
    "    print('selected training size is {}'.format(selected_size))\n",
    "    \n",
    "    Xtrain_selected = Xtrain[:selected_size,:]\n",
    "    ytrain_selected = ytrain[:selected_size,:]\n",
    "\n",
    "    hist = model.fit(Xtrain_selected, ytrain_selected,\n",
    "                     batch_size=64,\n",
    "                     epochs=100,\n",
    "                     verbose=1,\n",
    "                     callbacks=[early_stop],\n",
    "                     validation_data=(Xdev, ydev))\n",
    "    \n",
    "    results['data_size'] = i\n",
    "    results['Dev_mse'] = min(hist.history['val_mean_squared_error'])\n",
    "    \n",
    "    nn_results.append(results)\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print('used time in {} seconds.'.format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dev_mse</th>\n",
       "      <th>data_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.056182</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048510</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044618</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042093</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.041735</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040755</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.039818</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.038075</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.037814</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.036856</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dev_mse  data_size\n",
       "0   0.056182      0.001\n",
       "1   0.052614      0.002\n",
       "2   0.048510      0.004\n",
       "3   0.044618      0.008\n",
       "4   0.042093      0.016\n",
       "5   0.041735      0.020\n",
       "6   0.040755      0.030\n",
       "7   0.039818      0.040\n",
       "8   0.038075      0.080\n",
       "9   0.037814      0.100\n",
       "10  0.036856      0.150\n",
       "11  0.036613      0.200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_df = pd.DataFrame(nn_results)\n",
    "nn_df.to_csv('results_clip_fast/nn_results_with_5Layers_128H.csv', index=False)\n",
    "nn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_df_1= pd.read_csv('results/nn_results_with_4Layers_64H_rmsprop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build up NN model (trial version, the official version in .py file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.utils import shuffle\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.linear_model import LinearRegression, MultiTaskElasticNet, MultiTaskLasso\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, log_loss, accuracy_score\n",
    "import time\n",
    "# from sklearn.manifold import TSNE\n",
    "import joblib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.load('data/Xtrain.npy')\n",
    "Xdev = np.load('data/Xdev.npy')\n",
    "\n",
    "ytrain = np.load('data/ytrain.npy')\n",
    "ydev = np.load('data/ydev.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_params = {'fc_hidden_size': 64,\n",
    "              'lr': 0.0007126048096008777,\n",
    "              'n_fc_layers': 5,\n",
    "              'opt': 'rmsprop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0820 19:57:03.531414 140336225949440 deprecation.py:506] From /data/home/t-chepan/env/newlab/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Train on 1372529 samples, validate on 13863 samples\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "PATIENCE = 20\n",
    "\n",
    "n_features = Xtrain.shape[1]\n",
    "n_outputs = ytrain.shape[1]\n",
    "\n",
    "opt = optimizers.RMSprop(lr=hyp_params['lr'])\n",
    "\n",
    "inputs = keras.Input(shape=(n_features,), name='input_features')\n",
    "x = layers.Dense(128, activation='relu', name='dense_1')(inputs)\n",
    "x = layers.Dense(128, activation='relu', name='dense_2')(x)\n",
    "x = layers.Dense(128, activation='relu', name='dense_3')(x)\n",
    "x = layers.Dense(128, activation='relu', name='dense_4')(x)\n",
    "x = layers.Dense(128, activation='relu', name='dense_5')(x)\n",
    "outputs = layers.Dense(n_outputs, name='predictions')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=opt, \n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE)\n",
    "# checkpointer = ModelCheckpoint()\n",
    "\n",
    "print('# Fit model on training data')\n",
    "history = model.fit(Xtrain, ytrain,\n",
    "                    batch_size=64,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stop],\n",
    "                    validation_data=(Xdev, ydev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.125373</td>\n",
       "      <td>0.082850</td>\n",
       "      <td>0.125373</td>\n",
       "      <td>0.043606</td>\n",
       "      <td>0.084971</td>\n",
       "      <td>0.043606</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.151064</td>\n",
       "      <td>0.082882</td>\n",
       "      <td>0.151064</td>\n",
       "      <td>0.043469</td>\n",
       "      <td>0.081863</td>\n",
       "      <td>0.043469</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.164769</td>\n",
       "      <td>0.082713</td>\n",
       "      <td>0.164769</td>\n",
       "      <td>0.042821</td>\n",
       "      <td>0.082496</td>\n",
       "      <td>0.042821</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.125326</td>\n",
       "      <td>0.082725</td>\n",
       "      <td>0.125326</td>\n",
       "      <td>0.046434</td>\n",
       "      <td>0.083126</td>\n",
       "      <td>0.046434</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.137902</td>\n",
       "      <td>0.082841</td>\n",
       "      <td>0.137902</td>\n",
       "      <td>0.044403</td>\n",
       "      <td>0.085540</td>\n",
       "      <td>0.044403</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  mean_absolute_error  mean_squared_error  val_loss  \\\n",
       "8   0.125373             0.082850            0.125373  0.043606   \n",
       "9   0.151064             0.082882            0.151064  0.043469   \n",
       "10  0.164769             0.082713            0.164769  0.042821   \n",
       "11  0.125326             0.082725            0.125326  0.046434   \n",
       "12  0.137902             0.082841            0.137902  0.044403   \n",
       "\n",
       "    val_mean_absolute_error  val_mean_squared_error  epoch  \n",
       "8                  0.084971                0.043606      8  \n",
       "9                  0.081863                0.043469      9  \n",
       "10                 0.082496                0.042821     10  \n",
       "11                 0.083126                0.046434     11  \n",
       "12                 0.085540                0.044403     12  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_squared_error  val_mean_squared_error  epoch\n",
      "2            0.108347                0.042028      2\n"
     ]
    }
   ],
   "source": [
    "best_exp = hist.loc[hist['val_mean_squared_error'] == min(hist['val_mean_squared_error']),\n",
    "                    ['mean_squared_error', 'val_mean_squared_error', 'epoch']]\n",
    "print(best_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4XNWZ5/Hvq8WWsCzJi2xrQdgNBltgYQthIISAMTQmLIZJOoljMkDS8XQmJBBCCNDpNE0m3WTrgWTIQidA0mFwZ8MwLHEMgZDEBDC2Y4MMQRAvkndjy5t2vfPHvZJLsuSqkqpUJen3eZ566t5bp+59q1Sqt84595xr7o6IiMixZKQ6ABERSX9KFiIiEpWShYiIRKVkISIiUSlZiIhIVEoWIiIS1aAnCzN7wMx2mtlrfTxuZvZtM6s1s3VmVjXYMYqISHepqFk8BCw4xuOXAtPD2xLge4MQk4iIHMOgJwt3fwF49xhFFgI/8cCfgEIzKx6c6EREpDdZqQ6gF6XAloj1unDbtp4FzWwJQe2DMWPGnDFjxoxBCVBEZLh49dVXd7t7UbRy6ZgsYubu9wP3A1RXV/uqVatSHJGIyNBiZptiKZeOZ0PVA8dHrJeF20REJEXSMVk8Dvz38Kyos4EGdz+qCUpERAbPoDdDmdkjwAXARDOrA/4ZyAZw9+8DTwHvB2qBw8D1gx2jiIh0N+jJwt0XRXncgU8PUjgikgZaW1upq6ujqakp1aEMWzk5OZSVlZGdnd2v5w/pDm4RGR7q6uoYO3YsU6dOxcxSHc6w4+7s2bOHuro6pk2b1q99pGOfhYiMME1NTUyYMEGJIknMjAkTJgyo5qZkISJpQYkiuQb6/ipZiIhIVEoWIjLi7dmzh9mzZzN79mymTJlCaWlp13pLS0tM+7j++ut58803Yz7mD3/4Q4qKirqOM3v27LieP9jUwS0iI96ECRNYu3YtAHfeeSd5eXnccsst3cq4O+5ORkbvv7EffPDBuI+7ePFi7rnnnj4fb2trIyvryNd0tBgitbe3k5mZGXdMfVHNQkSkD7W1tVRUVLB48WJOPfVUtm3bxpIlS6iurubUU0/lrrvu6ir73ve+l7Vr19LW1kZhYSG33XYbp59+Oueccw47d+6M+ZjPPPMMF1xwAZdffjmzZs3qNYaf/vSnzJo1i9NOO4077rgDoOu4N910E5WVlbz88ssJfS9UsxCRtPIv/+91arbuT+g+K0ry+ecrTu3Xc9944w1+8pOfUF1dDcDdd9/N+PHjaWtrY968eXzwgx+koqKi23MaGho4//zzufvuu7n55pt54IEHuO22247a98MPP8zzzz/ftd75Bb9q1SpqamooLy+ntra2Wwx1dXV86UtfYtWqVRQUFHDRRRfxxBNPsGDBAhoaGnjf+953zNpKf6lmISJyDCeeeGJXogB45JFHqKqqoqqqig0bNlBTU3PUc3Jzc7n00ksBOOOMM9i4cWOv+168eDFr167tuo0aNQqAc845h/Ly8l5jeOmll7jwwguZOHEi2dnZfPSjH+WFF14AYNSoUVx99dUJed09qWYhImmlvzWAZBkzZkzX8ltvvcW9997Lyy+/TGFhIddcc02vYxc6v/QBMjMzaWtr6/cxe1vvS25ubtJOQVbNQkQkRvv372fs2LHk5+ezbds2li9fPugxnHXWWTz33HPs2bOHtrY2li5dyvnnn5/046pmISISo6qqKioqKpgxYwYnnHAC55577oD217PP4gc/+EHU55SVlfGVr3yFCy64AHfniiuu4LLLLou79hIvC+btG/p08SORoWvDhg3MnDkz1WEMe729z2b2qrtX9/GULmqGEhGRqJQsREQkKiULERGJSslCRESiUrIQEZGolCxERCQqJQsRGfHmzZt31AC7e+65h0996lPHfF5eXl6v2zMzM7tNPX733XcnLNZU0aA8ERnxFi1axNKlS7nkkku6ti1dupSvf/3r/dpfbm5u15Tnfek5hXjP6cj7Emu5RFPNQkRGvA9+8IM8+eSTXRc62rhxI1u3buW8887j4MGDzJ8/n6qqKmbNmsVjjz3W7+NMnTqVL37xi1RVVfHzn/+cCy64gJtuuonq6mruvfdeNm7cyIUXXkhlZSXz589n8+bNAFx33XX8wz/8A2eddRa33nprQl5zvFSzEJH08vRtsH19Yvc5ZRZc2ndT0Pjx45k7dy5PP/00CxcuZOnSpXzoQx/CzMjJyeHRRx8lPz+f3bt3c/bZZ3PllVcec8K+xsZGZs+e3bV+++238+EPfxgILrS0evVqAL7//e/T0tJC5+wTV1xxBddeey3XXnstDzzwAJ/97GdZtmwZAHV1daxcuTKhFzSKh5KFiAhHmqI6k8WPfvQjILg63R133MELL7xARkYG9fX17NixgylTpvS5r2M1Q3Umjd7WX3zxRX71q18B8LGPfaxbLeLv/u7vUpYoQMlCRNLNMWoAybRw4UI+97nPsXr1ag4fPswZZ5wBBJP97dq1i1dffZXs7GymTp3a67Tkserv9OOxlksW9VmIiBCc2TRv3jw+/vGPs2jRoq7tDQ0NTJo0iezsbJ577jk2bdqUtBje8573sHTpUiBIUuedd17SjhUv1SxEREKLFi3i6quv7vrChuBqdldccQWzZs2iurqaGTNmRN1Pzz6LBQsWxHT67He+8x2uv/56vvGNb1BUVMSDDz7YvxeSBJqiXERSTlOUDw5NUS4iIkmlZCEiIlEpWYhIWhguTeLpaqDvr5KFiKRcTk4Oe/bsUcJIEndnz5495OTk9HsfOhtKRFKurKyMuro6du3alepQhq2cnBzKysr6/XwlCxFJuezsbKZNm5bqMOQY1AwlIiJRpSRZmNkCM3vTzGrN7LZeHi83s+fMbI2ZrTOz96ciThERCQx6sjCzTOA+4FKgAlhkZhU9in0J+Jm7zwE+Anx3cKMUEZFIqahZzAVq3f0dd28BlgILe5RxID9cLgC2DmJ8IiLSQyqSRSmwJWK9LtwW6U7gGjOrA54CPtPbjsxsiZmtMrNVOotCRCR5YkoWZjY+hlthAuNaBDzk7mXA+4H/NLOjYnX3+9292t2ri4qKEnh4ERGJFOups1vDW9+XhoJMoDyGfdUDx0esl4XbIn0CWADg7i+aWQ4wEdgZY7wiIpJAsSaLDWFnc5/MbE2M+3oFmG5m0wiSxEeAj/YosxmYDzxkZjOBHEDtTCIiKRJrn8U5CSqDu7cBNwDLgQ0EZz29bmZ3mdmVYbHPA580sz8DjwDXueYBEBFJmag1CzO7GPiQmd3n7mvNbIm739+znLvHfJ1Bd3+KoOM6ctuXI5ZrgHNj3Z+IiCRXLM1QHwc+BXzJzMYDs6OUFxGRYSaWZqgD7r7P3W8B/hY4M8kxiYhImoklWTzZueDutwE/SV44IiKSjqImC3d/rMf6d5IXjoiIpKN4BuWVJDsYERFJT7GeOvtN4NrOFTNbaWY/M7PbzKznVB0iIjLMxJoszgDujlgfC/yIYFT17YkOSkRE0kusI7ibewyK+627Lzez3wAvJiEuERFJI7HWLJrM7ITOFXe/Mbx3IDsZgYmISPqINVl8FVhmZjMiN5pZMbqOt4jIsBfTF33Y5JQPPGdma4HXwoc+APxjsoITEZH0EHOtwN1/bmZPElxf4lSgEbja3f+crOBERCQ9xJQszOxa4FsEzVZPAJ929wPJDExERNJHrH0W/wRcDMwANgH/mrSIREQk7cTaDLXf3TsvbvRPZvZSsgISEZH0E2uyKDazJcAbBBcs0umyIiIjSKzJ4p+BWcDi8D7PzJ4C/gysc/dHkhSfiIikgVhPne12ZTwzKyNIGpUEZ0cpWYiIDGOxng01n6AGsQvA3euAOuDpJMYmIiJpItZmqBXATjPrIBiQtx5YF96/7u7NSYpPRETSQKzJ4jPAJ4CfASuBUwhmor0OmAlMSUZwIiKSHmIaZ+Hu9wHnAg7cA7QCN7r7PHdXohARGeZiHZSHuze6+9eAecBJwMtmdlbSIhMRkbQRawf3+whGb88gaHaaBBwAJiQvNBERSRex9lk8D6wFlgLfdveNyQpIRETST6zJ4lPAacBlwOfNbA/BmVDrgdfcfVmS4hMRkTQQ66C8H0Su9xiU9wFAyUJEZBjr11XuNChPRGRkielsKDNbnYgyIiIyNMVas5hpZuuO8bgBBQmIR0RE0lCsyWJGDGXaBxKIiIikr1g7uDclOxAREUlfMY/gFhGRkSvmZGGB45MZjIiIpKd45oZy4KlEHNTMFpjZm2ZWa2a39VHmQ2ZWY2avm9n/TcRxRUSkf+IdZ7HazM5091f6e0AzywTuAy4mGKvxipk97u41EWWmA7cD57r7XjOb1N/jiYjIwMWbLM4CFpvZJuAQwSmz7u6VcexjLlDr7u8AmNlSYCFQE1Hmk8B97r6X4AA744xTREQSKN5kcUkCjlkKbIlYryNIQpFOBjCzPwKZwJ3u/uueOzKzJcASgPLy8gSEJiIivYnrbKjwFNpC4IrwVpik02qzgOnABcAi4D/MrLCXeO5392p3ry4qKkpCGCIiAnEmCzO7EXiY4HoWk4Cfmtln4jxmPRB5VlVZuC1SHfC4u7e6+1+BvxAkDxERSYF4x1l8AjjL3b/s7l8GziboX4jHK8B0M5tmZqOAjwCP9yizjKBWgZlNJGiWeifO44iISILEmyyM7tN6tIfbYububcANwHJgA/Azd3/dzO4ysyvDYsuBPWZWAzwHfMHd98QZq4iIJEi8HdwPAi+Z2aPh+lXAj+I9qLs/RY8xG2FNpXPZgZvDm4iIpFjMycLMDPg5wSVW3xtuvt7d1yQhLhERSSMxJwt3dzN7yt1nAbp2hYjICBJvn8VqMzszKZGIiEjaSsUIbhERGWLi7bNYAujaFiIiI0y8fRb3hX0WIiIygqjPQkREoupPn8U1ZrYR9VmIiIwYqZh1VkREhpiYmqHM7FbomnV2rrtv6rwB/yOZAYqISOrF2mfxkYjl23s8tiBBsYiISJqKNVlYH8u9rYuIyDATa7LwPpZ7WxcRkWEm1g7u081sP0EtIjdcJlzPSUpkIiKSNmJKFu6emexAREQkfcU7KE9EREYgJQsREYlKyUJERKJSshARkajiShYWuMbMvhyul5vZ3OSEJiIi6SLemsV3gXOAReH6AeC+hEYkIiJpJ+5ZZ929yszWALj7XjMblYS4REQkjcRbs2g1s0zCUdtmVgR0JDwqERFJK/Emi28DjwKTzOyrwB+Af014VCIiklbivQb3C8CrwHyCqT6ucvcNSYpNRETSRLzX4H4qvAb3G0mMSURE0oyuwS0iIlH15xrci81sE7oGt4jIiKFrcIuISFRxJQt332Rm44DpdL+OxaaERiUiImklrmRhZn8P3AiUAWuBs4EXgQsTH5qIiKSLeDu4bwTOBDa5+zxgDrAv4VGJiEhaiTdZNLl7E4CZjXb3N4BTEh+WiIikk3g7uOvMrBBYBqwws72ov0JEZNiLt4P76nDxTjN7DigAnk54VCIiklbi7eD+ci+bZwN3xbmfBcC9QCbwQ3e/u49yHwB+AZzp7qviOYaIiCROvH0WhyJu7cClwNR4dhDOWntf+NwKYJGZVfRSbixBh/pLccYoIiIJFm8z1Lci183sm8DyOI85F6h193fCfSwFFgI1Pcp9Bfga8IU49y8iIgk20GtwH0cw5iIepcCWiPW6cFsXM6sCjnf3J4+1IzNbYmarzGzVrl274gxDRERiFW+fxXrCCx8R9DcUEWd/RQzHyAD+HbguWll3vx+4H6C6utqjFBcRkX6K99TZyyOW24Ad7t4W5z7qgeMj1svCbZ3GAqcBzweX0GAK8LiZXalObhGR1Ih7bqgEHPMVYLqZTSNIEh8BPhpxjAZgYue6mT0P3KJEISKSOvE2Q918rMfd/d+j7cPd28zsBoKO8UzgAXd/3czuAla5++PxxCQiIskXbzNUNcHcUJ1f6FcALwNvxbMTd38KeKrHtt7GcODuF8QZo4iIJFi8yaIMqHL3AwBmdifwpLtfk+jAREQkfcR76uxkoCVivSXcJiIiw1i8NYufAC+b2aMEl1S9Cngo0UGJiEh6ifdsqK+a2dPAeQTjLa5z9zVJiUxERNJGTM1QZnammU0BcPfVBBc8ugi43szGJzE+ERFJA7H2WfyAsK/CzN4H/BvwY6CBcAS1iIgMX7E2Q2W6+7vh8oeB+939l8AvzWxtckITEZF0EWvNItPMOhPLfOC3EY/F20kuIiJDTKxf9I8AvzOz3UAj8HsAMzuJoClKRESGsZiSRXgW1LNAMfAbd++c4TUD+EyyghMRkfQQcxOSu/+pl21/SWw4IiKSjgZ68SMRERkBlCxERCQqJQsREYkq3utZjAY+AEyNfK67J/TSqiIikl7iHSPxGMGpsq8CzYkPR0RE0lHc17Nw9wVJiURERNJWvH0WK81sVlIiERGRtBVvzeK9wHVm9leCZigD3N0rEx6ZiIikjXiTxaVJiUJERNJavBc/2mRm44DpQE7EQ5sSGpWIiKSVeE+d/XvgRqAMWAucDbwIXJj40EREJF3E28F9I3AmsMnd5wFzCK6aJyIiw1i8yaLJ3ZsgGKDn7m8ApyQ+LBERSSfxdnDXmVkhsAxYYWZ7UX+FiMiwF28H99Xh4p1m9hxQAPw64VGJiEhaiasZygLXmNmX3f13BJ3cs5MTmoiIpIt4+yy+C5wDLArXDwD3JTQiERFJO/H2WZzl7lVmtgbA3fea2agkxCUiImkk3ppFq5llAg5gZkVAR8KjEhGRtBJvsvg28Cgw2cy+CvwB+LeERyUiImkl3rOhHjazV4H54aaF4VgLEREZxmJKFmb2eM9N4f0lZoa7X5nYsEREJJ3EWrM4B9gCPAK8xJFkISIiI0CsfRZTgDuA04B7gYuB3e7+u3C8RVzMbIGZvWlmtWZ2Wy+P32xmNWa2zsyeNbMT4j2GiIgkTkzJwt3b3f3X7n4twUyztcDzZnZDvAcMz6a6j+DaGBXAIjOr6FFsDVAdXlTpF8DX4z2OiIgkTswd3GY2GriMYEDeVI6cGRWvuUCtu78T7ncpsBCo6Szg7s9FlP8TcE0/jiMiIgkSawf3TwiaoJ4C/sXdXxvAMUsJ+j861QFnHaP8J4Cn+4hrCbAEoLy8fAAhiYjIscTaZ3ENwdXxbgRWmtn+8HbAzPYnKzgzuwaoBr7R2+Pufr+7V7t7dVFRUbLCEBEZ8WKqWbh7vIP3jqUeOD5ivSzc1o2ZXQT8I3C+uzcn8PgiIhKnRCaBWL0CTDezaeG8Uh8Buo3jMLM5wA+AK919ZwpiFBGRCIOeLNy9DbgBWA5sAH7m7q+b2V1m1jm47xtAHvBzM1vby6BAEREZRPHOOpsQ7v4UQWd55LYvRyxfNOhBiYhIn1LRDCUiIkNMSmoWIiKD4UBTK1v3NbF1XyP1+xrZGt62729iZnE+l1eWUFVeiJlmMIpGyUJEhqS29g52HmiOSARN1O873C05HGhq6/acrAxjSkEOE/JG8/CfNvPgHzdSWpjL+2dN4fLKEirLCpQ4+qBkISJp6UBTa1dtoD5MAEduTWzf30R7h3d7TuFx2ZQU5FI27jjOmjaeksLcrltpYS5FY0eTmREkg/1NrTxTs4Mn1m3joZUb+Y/f/5Xjx+dy2awSLq8s5tSSfCWOCObu0UsNAdXV1b5q1apUhyEicWpr7+DNHQdYvXkfazbvpWbr/j5rBcWFOZQUBF/8RxJBTtf6mNH9+/3bcLiV5TXbeXLdNv5Yu5u2DmfqhOO4rLKYyytLmDFl7LBNHGb2qrtXRy2nZCEig2nXgWbWbN7Lmi1BclhX18DhlnYAJuaNorKskPLxx1FSmNOtVjAx70itIJn2Hmph+evbeWLdNla+vZsOhxOLxnBZZQlXVBYzffLYpMcwmJQsYvTY2nq2vHuYkyblcdKkPE6YMIbsTJ0kNpwcaGple0MT2xqa2N4QNF8Ey41MKcjhopmTOfekieRkZ6Y61GGnpa2DDdv2dyWH1Zv3suXdRiCoKZxaks+c8nHMKS+kqnwcZeNy0+oX/O6Dzfz6te08sW4rL/31Xdzh5Ml5XF5ZwmWVxZxYlJfqEAFw936/b0oWMfrcf63l0TVHZhvJyjBOmHAcJxbldSWQkyblcWJRXr+ruJIc7k5DY2tXEuhMANu6JYQmDja3HfXciXmjmDQ2h83vHuZgcxs52RmcN72Iiysmc+GMSUzMG52CVzT0bW9oOpIYNu1lfX0DzW0dAEzOH01V+TiqwuRwWmnBkErQOw808fT6oKnqlU1B4gjOqCrm8spiTpgwJuHH7Ohw3j3cEvzIaWhi2/4mdoSf9R37m9jW0Mj2hiZ++T/fw4wp+f06hpJFHA41t/H2roO8vesgtTuP3DbtOUxbRAdaSUEOJ4aJIzKRTBgzKq1+DQ0Hkf8k3ZJA53r4j9LU2tHteWYwaexophTkUpyfw5SCHIoLOu9zKS7IYVL+aEZnBV9SLW0d/OmdPTyzYQfP1Oxga0MTZlBVPo6LZk7m4opJnFiUp79vL5pa23l9a1hrCPsbtjY0ATAqM4PTSvPDxBAkh5LC3BRHnDjbG5p4av02nli3ldWb9wEwq7SAyyqLuWxWMcePPy7qPlrbO9h1oLlbjXd7QyPb9zd3fd537m+mpb37Zzwzw8LPeA5Tws/4x8+dFtMxe6NkkQCt7R1s2nOI2p2HuiWSt3cd7GpjheAMjJOKutdCTpqUR2lhLhmD0MY6nDQ0tvKD373Nj1du5FDEewxBrW9yfuSXf06QFApyurYXjR3d72ZEd6dm235W1OzgmQ07eK0+mFB52sQxXDRzEhfNnMwZJ4wjawQ2U7o7dXsbWRs2Ja3ZvI+arfu7vshKC3OpOmEcc44vZE55IRUl+V0Jebir39fIU+u28cT6bfx5S5A4Tj++kCsqi6kozmfHgbAmEPFDZ3tDE7sONtPz63d0Vka3z/OUglym5Ac/fjo/84nuu1GySKKODmfb/qYgcew8SG2YSN7eeZA9h1q6yuVkZ/A3E48kkLJxRzrrphTkMCpr5H3p9KWptZ0fr9zId59/m4bGVi6rLGbu1PHdagYTx4we1OS7dV8jz76xkxU1O3jx7d20tjvjjstm3oxJXDxzMuedXETeMGyadHe2NjSxvm4f6+sbWFfXwPr6BvYdbgWCz3VlWZAU5hw/jqryQibl56Q46vSw5d3DPBnWODp/bHTKz8miuCCXyQU5FOfnBPfhZ3tKmBwKcrMHvRarZJEiew+1ULsrTCIRiaRub2O3cmZQlDe6K3n0PPOjpDCXcccN/gdnsLW1d/CLV+u455m32L6/ifNPLuLWBadwaklBqkPr5kBTK79/azfP1Ozgt2/uZN/hVkZlZnDOiRO4uGIyF82czJSCofeF6e7s2N/Murp9vFbfwLr6BtbXNXT96MnKME6ePJbKsgJOKy3g9LJCZhSP1UkgMdi4+xBb9wUnUUwpyOG4Uen5w0LJIs00tbazvaGp22jTrfsa2dpwZBqCnu3vOdkZR5JHwdHnlE8pyBlSHYSR3J2nX9vON3/zJu/sOsSc8kJuvWQG55w4IdWhRdXW3sGqTXt5pmYHKzbsYNOew0DQZh30c0xmZnF6npe/80BTkBTqgqSwrr6BXQeCy8VkZhjTJ+Uxq7SgKznMLM4fsp8xiY2SxRDj7uw93HrUHDb1EaNXO/+pI03MG01pRK3kzKnjmTejKK3bi/9Yu5uv/foN1tU1MH1SHl+45BQurpicll+u0bg7tTsPsiLsIF+zZR/uQRv+RTMncVHFZM6aNiElTY57Djazvv5IUlhf18D2/UEHtBmcVJTHrLICKksLmFVWSEVxPrmj0vdzI8mhZDEMNbcFtZNuNZOI5FIf1k7yc7K4rLKYhbNLmTt1fNp0sq+va+Dry9/g92/tpqQgh89dfDL/rapsUAZaDZZdB5r57Rs7WFGzkz/U7qKptQMzyMnKJHdUJjlZGeRkZzI6O5Pc7GA5uEUsZwXruRGPBeW7l83tfCwrk6xMo3bnwa4aw/r6Bur3BU2fZvA3E8cwK0wKlWUFVBTn61RwAZQsRqS29g7+ULubx9ZuZfnr2znc0k5JQQ5Xzi7lqjkl/T4Pe6De2XWQb634C0+u28a447L59LyTuObsE4Z980ZjSzt/rN3Nurp9NLa209jaTlNrB03d7ttpauuxHi63dfTvf3NaZ2IoLWBWWQGnluQzNic7wa9OhgslixHucEsbK2p2sGxNPS+8tZv2DmfGlLEsnF3Kwtklg3LO+479TdzzzFv8bNUWRmdl8PfvncYn3/c3+uKKUWt798TS3NZOY0tHmFyObG9sbae1vYNpE8ZwamkBBbl6fyV2ShbSZffBZp5ct41la+tZs3kfZjB36niumlPK+08rpuC4xH65NBxu5Xu/e5uHVv6V9g7no3PLueHC6RSN1ahokXSjZCG92rTnEI+t3cqyNfW8s/sQozIzmDejiKtmlzJvxqQBNQ01trTz0MqNfO/5Wg40t7Hw9BJuvvgUyif0b2SpiCSfkoUck7uzvr6BZWu28vift7L7YDNjc7J4/2nFLJxTwtnTJsTcMd7a3sHPV9Vx77N/Ycf+Zi6cMYlb/vYUKkpS00ciIrFTspCYtbV3sPLtPSxbW8/y17ZzqKWd4oIcrjy9hIWzS/scM9DREYyV+NZv3uSd3Yc444RxfHHBDOZOG5+CVyEi/aFkIf3S2NLOig07eGxNPb/7yy7aOpyTJ+dx1ZxSFs4upTTsGP/DW8FYifX1DZw8OY9bL5nB/JmThuRYCZGRTMlCBuzdQy08uX4by9bU8+qmvUDQMZ6ZYbz4zh5KC3O5+eKTuWpO6bAaKyEykihZSEJtefcwj62tZ9narTQ0tvKp809k8dnlaT1SXESiU7IQEZGoYk0WmjpSRESi0uQwIiKJ5g5tzeDtkJENGVmQMbR/mytZPHkLvLUcMLCMXm7W4z689Vreji4XecvMhsxR4a235chto6KU7WPZDLwjvHnEco91ej7WeaOP7ZHPCZsuzcL3IeK+673p5bFu90Qv19Ee/LN1dIT37T3uE7C9298rM7jPyIzYnnn7AbiTAAAHkklEQVTk8YyI5V63dS7b0WV7+3vgPbb19njk9mP9/TzY1ulYzctHPXas50Vrpo44saHbmXB9be/59L6eE/E/d9RnK/IxjvFYb8/jyPb2NmhrCr7U25uPLMd839z34+1HzxAdfF6ywlt28BnJzI7YlhXjeuaRBNS5ft7nYdzUKH+rgVGyKDoFWg728eXa+Y9JH1+gPf7RO9r7/iLu6ICOVmhvgfbO+x7LIpI+snIga/TR95nhck5B32U67y0DOtqC74aO1mC5vbXHeltYpi3c1h6WiVhvORRRpu3o/cxdkvy3I+lHSHdzPwl8MtVRBMmmryTSHiXJtLcGv2Q6E06fNZ8otZ9uz+lZxrqX6/xV3Ot9Ry/biPKcXu4zMoNf6133GT3Wj7U9o5dyvWyHMJm395LgI7e1c9SPAm/vUdb72N7Rx98hYvmov1dvNdlj1XIjfml3Odav+x7rMf/67/GZjbo9xlpLz+d0vpdHfZ46f6T19lnrOMbzeu7Tg5p41qjev+g7a+nSRckiXZiFH9xRqY5EROQoQ7vHRUREBoWShYiIRKVkISIiUSlZiIhIVClJFma2wMzeNLNaM7utl8dHm9l/hY+/ZGZTBz9KERHpNOjJwswygfuAS4EKYJGZVfQo9glgr7ufBPxv4GuDG6WIiERKRc1iLlDr7u+4ewuwFFjYo8xC4Mfh8i+A+aYLJYiIpEwqxlmUAlsi1uuAs/oq4+5tZtYATAB2RxYysyVA59DFg2b2Zj9jmthz30OYXkv6GS6vA/Ra0tFAX8cJsRQa0oPy3P1+4P6B7sfMVsUyRe9QoNeSfobL6wC9lnQ0WK8jFc1Q9cDxEetl4bZey5hZFlAA7BmU6ERE5CipSBavANPNbJqZjQI+Ajzeo8zjwLXh8geB3/pwuUqTiMgQNOjNUGEfxA3AciATeMDdXzezu4BV7v448CPgP82sFniXIKEk04CbstKIXkv6GS6vA/Ra0tGgvI5hc1lVERFJHo3gFhGRqJQsREQkqhGfLKJNPTIUmNnxZvacmdWY2etmdmOqYxooM8s0szVm9kSqYxkIMys0s1+Y2RtmtsHMzkl1TP1lZp8LP1+vmdkjZpaT6phiZWYPmNlOM3stYtt4M1thZm+F9+NSGWMs+ngd3wg/X+vM7FEzK0zGsUd0sohx6pGhoA34vLtXAGcDnx6iryPSjcCGVAeRAPcCv3b3GcDpDNHXZGalwGeBanc/jeDklGSfeJJIDwELemy7DXjW3acDz4br6e4hjn4dK4DT3L0S+AtwezIOPKKTBbFNPZL23H2bu68Olw8QfCGVpjaq/jOzMuAy4IepjmUgzKwAeB/B2X24e4u770ttVAOSBeSGY5+OA7amOJ6YufsLBGdWRoqcVujHwFWDGlQ/9PY63P037t4Wrv6JYOxawo30ZNHb1CND9ksWIJyhdw7wUmojGZB7gFuBjlQHMkDTgF3Ag2GT2g/NbEyqg+oPd68HvglsBrYBDe7+m9RGNWCT3X1buLwdmJzKYBLk48DTydjxSE8Ww4qZ5QG/BG5y9/2pjqc/zOxyYKe7v5rqWBIgC6gCvufuc4BDDI2mjqOE7fkLCRJgCTDGzK5JbVSJEw76HdLjCMzsHwmapB9Oxv5HerKIZeqRIcHMsgkSxcPu/qtUxzMA5wJXmtlGgmbBC83sp6kNqd/qgDp376zl/YIgeQxFFwF/dfdd7t4K/Ap4T4pjGqgdZlYMEN7vTHE8/WZm1wGXA4uTNdvFSE8WsUw9kvbC6dt/BGxw939PdTwD4e63u3uZu08l+Hv81t2H5C9Yd98ObDGzU8JN84GaFIY0EJuBs83suPDzNp8h2lkfIXJaoWuBx1IYS7+Z2QKCZtsr3f1wso4zopNF2CnUOfXIBuBn7v56aqPql3OBjxH8Cl8b3t6f6qAEgM8AD5vZOmA28K8pjqdfwtrRL4DVwHqC744hM12GmT0CvAicYmZ1ZvYJ4G7gYjN7i6DmdHcqY4xFH6/j/wBjgRXh//73k3JsTfchIiLRjOiahYiIxEbJQkREolKyEBGRqJQsREQkKiULERGJSslCJEZm1h5xavLaRM5SbGZTI2cSFUk3g35ZVZEhrNHdZ6c6CJFUUM1CZIDMbKOZfd3M1pvZy2Z2Urh9qpn9NrzOwLNmVh5unxxed+DP4a1z2oxMM/uP8JoRvzGz3JS9KJEelCxEYpfboxnqwxGPNbj7LILRtPeE274D/Di8zsDDwLfD7d8GfufupxPMFdU5a8B04D53PxXYB3wgya9HJGYawS0SIzM76O55vWzfCFzo7u+EEzpud/cJZrYbKHb31nD7NnefaGa7gDJ3b47Yx1RgRXghHszsi0C2u/+v5L8ykehUsxBJDO9jOR7NEcvtqE9R0oiShUhifDji/sVweSVHLj26GPh9uPws8CnoutZ4wWAFKdJf+uUiErtcM1sbsf5rd+88fXZcOLNsM7Ao3PYZgqvkfYHginnXh9tvBO4PZwxtJ0gc2xBJY+qzEBmgsM+i2t13pzoWkWRRM5SIiESlmoWIiESlmoWIiESlZCEiIlEpWYiISFRKFiIiEpWShYiIRPX/AUQsvl8RicPeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [MPG]')\n",
    "    plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
    "           label = 'Val Error')\n",
    "    plt.ylim([0,1.0])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "    plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
    "           label = 'Val Error')\n",
    "    plt.ylim([0,1.0])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AR_exchange_06</th>\n",
       "      <th>AR_sharepoint_06</th>\n",
       "      <th>AR_skype_06</th>\n",
       "      <th>AR_teams_06</th>\n",
       "      <th>AR_od4b_06</th>\n",
       "      <th>AR_onenote_06</th>\n",
       "      <th>AR_word_06</th>\n",
       "      <th>AR_excel_06</th>\n",
       "      <th>AR_powerpoint_06</th>\n",
       "      <th>AR_outlook_06</th>\n",
       "      <th>AR_officelient_06</th>\n",
       "      <th>AR_eslt_06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.350000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.557895</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.055263</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.185366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.417857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.154326</td>\n",
       "      <td>0.919502</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>0.961253</td>\n",
       "      <td>0.983018</td>\n",
       "      <td>0.634522</td>\n",
       "      <td>0.974187</td>\n",
       "      <td>0.983650</td>\n",
       "      <td>0.894815</td>\n",
       "      <td>0.932441</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>2.245882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.940762</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>-0.005533</td>\n",
       "      <td>-0.009961</td>\n",
       "      <td>0.018362</td>\n",
       "      <td>0.793438</td>\n",
       "      <td>0.994242</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.900096</td>\n",
       "      <td>0.997751</td>\n",
       "      <td>0.989207</td>\n",
       "      <td>0.927893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.521717</td>\n",
       "      <td>0.205672</td>\n",
       "      <td>0.304841</td>\n",
       "      <td>0.070601</td>\n",
       "      <td>0.073494</td>\n",
       "      <td>0.923583</td>\n",
       "      <td>0.998731</td>\n",
       "      <td>1.003279</td>\n",
       "      <td>0.954310</td>\n",
       "      <td>0.990514</td>\n",
       "      <td>0.969758</td>\n",
       "      <td>1.498348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AR_exchange_06  AR_sharepoint_06  AR_skype_06  AR_teams_06  AR_od4b_06  \\\n",
       "0        2.350000          1.000000     1.000000     1.000000    1.000000   \n",
       "1        0.954545          0.000000     0.000000     0.000000    0.020833   \n",
       "2        1.557895          0.289474     0.055263     0.434211    0.185366   \n",
       "3        2.154326          0.919502     0.017316     0.961253    0.983018   \n",
       "4        0.940762          0.006363    -0.005533    -0.009961    0.018362   \n",
       "5        1.521717          0.205672     0.304841     0.070601    0.073494   \n",
       "\n",
       "   AR_onenote_06  AR_word_06  AR_excel_06  AR_powerpoint_06  AR_outlook_06  \\\n",
       "0       0.000000    1.000000     1.000000          0.000000       1.000000   \n",
       "1       1.000000    1.000000     1.000000          1.000000       1.000000   \n",
       "2       1.000000    1.000000     1.000000          1.000000       1.000000   \n",
       "3       0.634522    0.974187     0.983650          0.894815       0.932441   \n",
       "4       0.793438    0.994242     0.997297          0.900096       0.997751   \n",
       "5       0.923583    0.998731     1.003279          0.954310       0.990514   \n",
       "\n",
       "   AR_officelient_06  AR_eslt_06  \n",
       "0           1.000000    2.375000  \n",
       "1           1.000000    0.875000  \n",
       "2           1.000000    1.417857  \n",
       "3           0.945302    2.245882  \n",
       "4           0.989207    0.927893  \n",
       "5           0.969758    1.498348  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_show = Xtest[:3]\n",
    "ytest_show = ytest[:3]\n",
    "predictions = model.predict(Xtest_show)\n",
    "# print('predictions shape:', predictions.shape)\n",
    "data = np.concatenate((ytest_show,predictions), axis=0)\n",
    "data_df = pd.DataFrame(data=data, columns=output_cols)\n",
    "data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94076216,  0.00636315, -0.00553319, -0.00996105,  0.01836217,\n",
       "         0.7934381 ,  0.9942418 ,  0.9972968 ,  0.9000956 ,  0.99775076,\n",
       "         0.9892066 ,  0.927893  ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(Xtest_show[1].reshape((1, Xtest_show[1].shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is for test example 0\n",
      "AR_exchange_06_true: 2.35\n",
      "AR_exchange_06_pred: 2.154325008392334\n",
      "==================================================\n",
      "AR_sharepoint_06_true: 1.0\n",
      "AR_sharepoint_06_pred: 0.919501781463623\n",
      "==================================================\n",
      "AR_skype_06_true: 1.0\n",
      "AR_skype_06_pred: 0.01731596142053604\n",
      "==================================================\n",
      "AR_teams_06_true: 1.0\n",
      "AR_teams_06_pred: 0.9612530469894409\n",
      "==================================================\n",
      "AR_od4b_06_true: 1.0\n",
      "AR_od4b_06_pred: 0.9830180406570435\n",
      "==================================================\n",
      "AR_onenote_06_true: 0.0\n",
      "AR_onenote_06_pred: 0.634522020816803\n",
      "==================================================\n",
      "AR_word_06_true: 1.0\n",
      "AR_word_06_pred: 0.9741873145103455\n",
      "==================================================\n",
      "AR_excel_06_true: 1.0\n",
      "AR_excel_06_pred: 0.983650267124176\n",
      "==================================================\n",
      "AR_powerpoint_06_true: 0.0\n",
      "AR_powerpoint_06_pred: 0.894814670085907\n",
      "==================================================\n",
      "AR_outlook_06_true: 1.0\n",
      "AR_outlook_06_pred: 0.9324406385421753\n",
      "==================================================\n",
      "AR_officelient_06_true: 1.0\n",
      "AR_officelient_06_pred: 0.9453018307685852\n",
      "==================================================\n",
      "AR_eslt_06_true: 2.375\n",
      "AR_eslt_06_pred: 2.245882272720337\n",
      "==================================================\n",
      "********************\n",
      "This is for test example 1\n",
      "AR_exchange_06_true: 0.9545454545454546\n",
      "AR_exchange_06_pred: 0.9407621622085571\n",
      "==================================================\n",
      "AR_sharepoint_06_true: 0.0\n",
      "AR_sharepoint_06_pred: 0.0063631534576416016\n",
      "==================================================\n",
      "AR_skype_06_true: 0.0\n",
      "AR_skype_06_pred: -0.005533188581466675\n",
      "==================================================\n",
      "AR_teams_06_true: 0.0\n",
      "AR_teams_06_pred: -0.009961046278476715\n",
      "==================================================\n",
      "AR_od4b_06_true: 0.02083333333333333\n",
      "AR_od4b_06_pred: 0.018362171947956085\n",
      "==================================================\n",
      "AR_onenote_06_true: 1.0\n",
      "AR_onenote_06_pred: 0.7934380769729614\n",
      "==================================================\n",
      "AR_word_06_true: 1.0\n",
      "AR_word_06_pred: 0.9942417740821838\n",
      "==================================================\n",
      "AR_excel_06_true: 1.0\n",
      "AR_excel_06_pred: 0.9972968101501465\n",
      "==================================================\n",
      "AR_powerpoint_06_true: 1.0\n",
      "AR_powerpoint_06_pred: 0.9000955820083618\n",
      "==================================================\n",
      "AR_outlook_06_true: 1.0\n",
      "AR_outlook_06_pred: 0.9977507591247559\n",
      "==================================================\n",
      "AR_officelient_06_true: 1.0\n",
      "AR_officelient_06_pred: 0.9892066121101379\n",
      "==================================================\n",
      "AR_eslt_06_true: 0.875\n",
      "AR_eslt_06_pred: 0.9278929829597473\n",
      "==================================================\n",
      "********************\n",
      "This is for test example 2\n",
      "AR_exchange_06_true: 1.5578947368421054\n",
      "AR_exchange_06_pred: 1.5217167139053345\n",
      "==================================================\n",
      "AR_sharepoint_06_true: 0.2894736842105263\n",
      "AR_sharepoint_06_pred: 0.20567204058170319\n",
      "==================================================\n",
      "AR_skype_06_true: 0.05526315789473685\n",
      "AR_skype_06_pred: 0.3048413395881653\n",
      "==================================================\n",
      "AR_teams_06_true: 0.4342105263157895\n",
      "AR_teams_06_pred: 0.07060099393129349\n",
      "==================================================\n",
      "AR_od4b_06_true: 0.18536585365853656\n",
      "AR_od4b_06_pred: 0.07349404692649841\n",
      "==================================================\n",
      "AR_onenote_06_true: 1.0\n",
      "AR_onenote_06_pred: 0.9235831499099731\n",
      "==================================================\n",
      "AR_word_06_true: 1.0\n",
      "AR_word_06_pred: 0.9987313151359558\n",
      "==================================================\n",
      "AR_excel_06_true: 1.0\n",
      "AR_excel_06_pred: 1.003279447555542\n",
      "==================================================\n",
      "AR_powerpoint_06_true: 1.0\n",
      "AR_powerpoint_06_pred: 0.954310417175293\n",
      "==================================================\n",
      "AR_outlook_06_true: 1.0\n",
      "AR_outlook_06_pred: 0.9905139207839966\n",
      "==================================================\n",
      "AR_officelient_06_true: 1.0\n",
      "AR_officelient_06_pred: 0.9697580337524414\n",
      "==================================================\n",
      "AR_eslt_06_true: 1.4178571428571427\n",
      "AR_eslt_06_pred: 1.498348355293274\n",
      "==================================================\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ytest_show)):\n",
    "    print('This is for test example {}'.format(i))\n",
    "    \n",
    "    n = Xtest_show.shape[1]\n",
    "    predictions = model.predict(Xtest_show[i].reshape((1, n)))\n",
    "    \n",
    "    for j in range(len(ytest_show[i])):\n",
    "        print('{}_true: {}'.format(output_cols[j], ytest_show[i][j]))\n",
    "        print('{}_pred: {}'.format(output_cols[j], predictions[0][j]))\n",
    "        print('='*50)\n",
    "    \n",
    "    print('*'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the training configuration (optimizer, loss, metrics)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              # List of metrics to monitor\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Train the model by slicing the data into \"batches\"\n",
    "# of size \"batch_size\", and repeatedly iterating over\n",
    "# the entire dataset for a given number of \"epochs\"\n",
    "print('# Fit model on training data')\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=3,\n",
    "                    # We pass some validation for\n",
    "                    # monitoring validation loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "# The returned \"history\" object holds a record\n",
    "# of the loss values and metric values during training\n",
    "print('\\nhistory dict:', history.history)\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print('test loss, test acc:', results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model.predict(x_test[:3])\n",
    "print('predictions shape:', predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
